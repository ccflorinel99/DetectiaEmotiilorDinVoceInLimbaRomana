# -*- coding: utf-8 -*-
"""Licenta.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zm8THIod4dAwZiQaIp8h1gjq2U69q0FY
"""

!pip install pydub
!pip install scipy
!pip install tabulate # pentru creare tabele

# de pus referinta/ referinte
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
# type of generalized linear model (GLM) that uses a logistic function to model a binary dependent variable. It estimates the probability that a given input belongs to a particular class and then classifies it based on a threshold (supervised)
from sklearn.tree import DecisionTreeClassifier
# flowchart-like structure, where each internal node represents a feature(or attribute), each branch represents a decision rule, and each leaf node represents the outcome (supervised)
from sklearn.neural_network import MLPClassifier
# type of feedforward artificial neural network that consists of one or more layers of artificial neurons, called perceptrons. Each perceptron receives input from the previous layer and applies a non-linear activation function to it before passing the output to the next layer. The last layer of perceptrons is called the output layer and it generates the final predictions. The algorithm learns the weights of the perceptrons by minimizing the difference between the predicted output and the true output using an optimization algorithm, such as stochastic gradient descent. (supervised)
from sklearn.metrics import classification_report
import librosa
from sklearn.ensemble import RandomForestClassifier # multiple trees and combines them to make a decision by using "vote system" and the majority wins (supervised)
import os
import pickle
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC # find the best boundary (supervised)
from pydub import AudioSegment
from IPython.display import Audio
from IPython.display import display
import soundfile as sf

def path_exists(path):
  return os.path.exists(path)


class Output():
  def __init__(self):
    self.msg = ""

  def add(self, msg):
    if self.msg == "":
      self.msg = msg
    else:
      self.msg = self.msg + "\n" + msg

  def show(self):
    print(self.msg)

  def clear(self):
    self.msg = ""


class Error():
  def __init__(self):
    self.msg = ""
    self.out = Output()

  def add_error(self, msg):
    if self.msg == "":
      self.msg = msg
    else:
      self.msg = self.msg + "\n" + msg
  
  def path_not_found(self, path):
    self.add_error(f"{path} nu exista")

  def got_error(self):
    if self.msg == "":
      return False
    else:
      return True

  def clear(self):
    self.msg = ""

  def show(self):
    print(self.msg)


out = Output()
err = Error()

class AudioManipulation:
  def __init__(self):
    import sys
    self.py_version = sys.version.split(' ')[0]

  def load(self, file_path):
    global err
    if path_exists(file_path):
      audio = AudioSegment.from_wav(file_path)
      import soundfile as sf
      _ , sr = sf.read(file_path)  
      return audio, sr
    else:
      err.path_not_found(file_path)

  # STFT (Short-Time Fourier Transform) este o metodă utilizată pentru a analiza un semnal în timp și frecvență. Aceasta se face prin împărțirea semnalului în fragmente scurte de durată (numite "ferestre") și aplicarea unei transformări Fourier pe fiecare fragment. Aceasta permite analizarea semnalului în timp și frecvență simultan.
  # In acest caz, se utilizeaza functia numpy hanning pentru a obtine fereastra hanning si se prelungește audio cu câteva esantioane pentru a evita pierderea acestora la tăiere. Apoi, se utilizeaza functia fft din numpy pentru a efectua transformata Fourier rapida, si se returneaza spectrograma absoluta.
  def stft(self, audio, window_size=2048):
    audio_len = len(audio)
    window = np.hanning(window_size)
    audio = np.pad(audio, (window_size//2, window_size//2), mode='reflect')
    num_segments = (audio_len + window_size - 1) // window_size
    segments = np.zeros((num_segments, window_size))
    for i in range(num_segments):
        segment = audio[i*window_size:i*window_size+window_size]
        segments[i] = segment * window
    spectrogram = np.abs(np.fft.fft(segments, axis=1))
    return spectrogram

  def piptrack(self, audio, sr):
    # calculam diferenta de faza intre semnalul original si cel intarziat
    audio_delayed = audio[1:]
    audio_diff = audio_delayed - audio[:-1]
    audio_diff = np.square(audio_diff)

    # aplicam o fereastra de Hanning
    window = np.hanning(len(audio_diff))
    audio_diff = audio_diff * window

    # calculam integrala spectrului
    audio_diff = np.cumsum(audio_diff)

    # determinam pitch-ul
    pitch = sr / np.argmin(audio_diff)

    return pitch
  # Funcția piptrack implementată mai sus este o încercare de a replica comportamentul funcției librosa.piptrack din biblioteca Librosa. Aceasta funcție este utilizată pentru a estima oscilațiile de ton (pitch) în semnalul audio.
  # Pentru a realiza acest lucru, începe prin a aplica un filtru pas-bandă (band-pass filter) semnalului audio, utilizând funcția scipy.signal.butter. Filtru este creat prin specificarea unei frecvente de tăiere (cutoff frequency) pentru filtrul pas-bandă, care este de obicei setată la 75 Hz. Aceasta reduce semnalul audio la o bandă de frecvențe care conține tonurile vorbirii umane.
  # Apoi, funcția numpy.diff este utilizată pentru a calcula diferența dintre două valori consecutive din semnalul filtrat. Acest lucru se face pentru a identifica variațiile rapide de frecvență din semnal, care indică oscilațiile de ton.

class Preprocessing():
  def __init__(self, dir : str):
    global err
    global out
    self.dir = dir
    self.am = AudioManipulation()
    if not path_exists(dir): # verifica daca directorul exista sau nu
      err.path_not_found(dir)
    else:
      # listam fisierele din directorul dat ca parametru
      filenames = os.listdir(self.dir)

      # cream lista de tupluri formata din numele fisierelor audio si numele fisierelor txt asociate
      self.audio_txt_pairs = []
      for filename in filenames:
        if filename.endswith('.wav'):
          txt_filename = filename.replace('.wav', '.txt')
          full_path = os.path.join(self.dir, txt_filename)
          if path_exists(full_path):
            self.audio_txt_pairs.append((os.path.join(self.dir, filename), os.path.join(self.dir, txt_filename)))
          else:
            err.path_not_found(full_path)

  def preprocess_audio_file(self, audio_file, txt_file):
    global err
    global out
    if err.got_error():
      out.add("Ai de rezolvat una sau mai multe erori inainte de a lucra cu functia preprocess_audio_file")
      return [0], 0
    else: 
      # incarcam fisierul audio
      audio, sr = self.am.load(audio_file)
      audios = []
    
      if(path_exists(txt_file)):
        with open(txt_file, 'r') as f:
          lines = f.readlines()
          out.add(f"txt file: {txt_file}, nr linii: {len(lines)}")
          # impartim fisierul audio in fragmente
          for line in lines:
            start = float(line[:line.find("[")].split(' ')[0].split('\t')[0])
            end = float(line[:line.find("[")].split(' ')[0].split('\t')[1])
            fragment_audio = audio[start:end]
            out.add(f"range {start} - {end}")
            # adaugam fragmentul audio la lista de fragmente
            audios.append(fragment_audio)
        f.close()
      else:
        err.path_not_found(txt_file)
    
      return audios, sr

  def extract_features(self, audio, sr):
    global err
    global out
    if err.got_error():
      out.add("Ai de rezolvat una sau mai multe erori inainte de a lucra cu functia extract_features")
      return [0, 0, 0, 0, 0, 0]
    else: 
      # transformare din oydub audiosegment in numpy array
      audio = np.asarray(audio.get_array_of_samples(),dtype = np.float64)
      # calculam amplitudinea semnalului
      amplitudes = np.abs(audio)

      # calculam spectrul de frecventa
      spectrogram = np.abs(self.am.stft(audio))

      # calculam rata de variatie a frecventei vorbirii
      pitch = self.am.piptrack(audio, sr)
      pitch = np.array([pitch])
      pitch_change = np.diff(pitch)
      pitch_change_rate = np.mean(pitch_change)

      # calculam lungimea silabelor
      syllable_lengths = []
      for i in range(len(audio) - 1):
        if audio[i] > 0 and audio[i + 1] < 0:
          syllable_lengths.append(i + 1 - sum(syllable_lengths))

      # calculam durata pauzelor
      pause_lengths = []
      for i in range(len(audio) - 1):
        if audio[i] == 0 and audio[i + 1] != 0:
          pause_lengths.append(i + 1 - sum(pause_lengths))

      # calculam rata de respiratie
      respiration_rate = 0
      if(sum(syllable_lengths) != 0):
        respiration_rate = len(syllable_lengths) / sum(syllable_lengths)

      # returnam caracteristicile
      return [np.mean(amplitudes), np.mean(spectrogram), pitch_change_rate, np.mean(syllable_lengths), np.mean(pause_lengths), respiration_rate]

  
  def preprocesare(self):
    global out
    global err
    if err.got_error():
      out.add("Ai de rezolvat una sau mai multe erori inainte de a lucra cu functia preprocesare")
      return 0, 0
    else: 
      # obtinem listele audio_files si txt_files
      audio_files = [pair[0] for pair in self.audio_txt_pairs]
      txt_files = [pair[1] for pair in self.audio_txt_pairs]

      # citim etichetele de emotie din fisierele txt
      labels = []
      for txt_file in txt_files:
        with open(txt_file, 'r') as f:
          lines = f.readlines()
          for line in lines:
            label = line[line.find("["):].split(' ')[0].replace("[", "").replace("]", "")
            labels.append(label)

      # extragem caracteristicile din fisierele audio
      X = []

      for i in range(len(self.audio_txt_pairs)):
        audio, sr = self.preprocess_audio_file(audio_files[i], txt_files[i])
        for j in range(len(audio)):
          features = self.extract_features(audio[j], sr)
          X = np.append(X, features)
        out.add(f"(inainte de nan_to_num) {txt_files[i]}, X = {X}")

        # la intoarcerea din functia extract_features, pitch_change_rate si respiration_rate au cele mai mari sanse sa dea nan
        X = np.nan_to_num(X)
        out.add(f"(dupa nan_to_num) {txt_files[i]}, X = {X}")
    
      # transformam etichetele de emotie in forma utilizabila de model
      le = LabelEncoder()
      y = le.fit_transform(labels)

      # Elimină lista suplimentară din interiorul lui np.array() atunci când se definește X
      X = np.resize(X, (y.shape[0], 1))
      
      return X, y

class Model:
  def __init__(self):
    # creeam modelele
    self.RandomForestClassifierModel = RandomForestClassifier()
    self.SVCModel = SVC()
    self.LogisticRegressionModel = LogisticRegression(max_iter=500)
    # daca lasam default (max_iter=100 default), atunci imi dadea eroarea STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
    # discutie: https://stackoverflow.com/questions/62658215/convergencewarning-lbfgs-failed-to-converge-status-1-stop-total-no-of-iter
    self.DecisionTreeClassifierModel = DecisionTreeClassifier()
    self.MLPClassifierModel = MLPClassifier()

  def save_models(self):
    global err
    global out

    if err.got_error():
      out.add("Ai de rezolvat una sau mai multe erori inainte de a salva modelele")
    else:
      with open("RandomForestClassifierModel.pkl", "wb") as f:
        # salvam modelul in fisier
        pickle.dump(self.RandomForestClassifierModel, f)
      out.add("RandomForestClassifierModel a fost salvat")

      with open("SVCModel.pkl", "wb") as f:
        # salvam modelul in fisier
        pickle.dump(self.SVCModel, f)
      out.add("SVCModel a fost salvat")

      with open("LogisticRegressionModel.pkl", "wb") as f:
        # salvam modelul in fisier
        pickle.dump(self.LogisticRegressionModel, f)
      out.add("LogisticRegressionModel a fost salvat")

      with open("DecisionTreeClassifierModel.pkl", "wb") as f:
        # salvam modelul in fisier
        pickle.dump(self.DecisionTreeClassifierModel, f)
      out.add("DecisionTreeClassifierModel a fost salvat")

      with open("MLPClassifierModel.pkl", "wb") as f:
        # salvam modelul in fisier
        pickle.dump(self.MLPClassifierModel, f)
      out.add("MLPClassifierModel a fost salvat")

  def load_models(self):
    with open("RandomForestClassifierModel.pkl", "rb") as f:
      # salvam modelul in fisier
      self.RandomForestClassifierModel = pickle.load(f)
    out.add("RandomForestClassifierModel a fost incarcat")

    with open("SVCModel.pkl", "rb") as f:
      # salvam modelul in fisier
      self.SVCModel = pickle.load(f)
    out.add("SVCModel a fost incarcat")

    with open("LogisticRegressionModel.pkl", "rb") as f:
      # salvam modelul in fisier
      self.LogisticRegressionModel = pickle.load(f)
    out.add("LogisticRegressionModel a fost incarcat")

    with open("DecisionTreeClassifierModel.pkl", "rb") as f:
      # salvam modelul in fisier
      self.DecisionTreeClassifierModel = pickle.load(f)
    out.add("DecisionTreeClassifierModel a fost incarcat")

    with open("MLPClassifierModel.pkl", "rb") as f:
      # salvam modelul in fisier
      self.MLPClassifierModel = pickle.load(f)
    out.add("MLPClassifierModel a fost incarcat")

  def train(self, x, y):
    global each
    global out

    if err.got_error():
      out.add("Nu poti antrena modelele daca ai erori")
    elif x.size == 0 and y.size == 0:
      err.add_error("Nu s-a realizat preprocesarea")
    else:
      self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(x, y, test_size=0.7, random_state=42) # 70% date de antrenare, 30% date de testare
      # random_state = 42 means that the split is reproducible, meaning that if the script is run again with the same random_state, the data will be split in the same way
      out.add(f"X_train: {self.X_train}")
      out.add(f"y_train: {self.y_train}")
      out.add(f"X_test: {self.X_test}")
      out.add(f"y_test: {self.y_test}")
      self.RandomForestClassifierModel.fit(self.X_train, self.y_train)
      self.SVCModel.fit(self.X_train, self.y_train)
      self.LogisticRegressionModel.fit(self.X_train, self.y_train)
      self.DecisionTreeClassifierModel.fit(self.X_train, self.y_train)
      self.MLPClassifierModel.fit(self.X_train, self.y_train)
      out.add("Modelele au fost antrenate")

  def accuracy_score(self, y_true, y_pred):
    num_correct = 0
    for i in range(len(y_true)):
        if y_true[i] == y_pred[i]:
            num_correct += 1
    return num_correct / len(y_true)

  def models_accuracy(self):
    global err
    global out
    if err.got_error():
      out.add("Ai una sau mai multe erori de rezolvat")
    else:
      # evaluam acuratetea modelului pe datele de testare
      self.y_pred_RandomForestClassifier = self.RandomForestClassifierModel.predict(self.X_test)
      self.y_pred_SVC = self.SVCModel.predict(self.X_test)
      self.y_pred_LogisticRegression = self.LogisticRegressionModel.predict(self.X_test)
      self.y_pred_DecisionTreeClassifier = self.DecisionTreeClassifierModel.predict(self.X_test)
      self.y_pred_MLPClassifier = self.MLPClassifierModel.predict(self.X_test)

      self.accuracy_RandomForestClassifier = self.accuracy_score(self.y_test, self.y_pred_RandomForestClassifier)
      self.accuracy_SVC = self.accuracy_score(self.y_test, self.y_pred_SVC)
      self.accuracy_LogisticRegression = self.accuracy_score(self.y_test, self.y_pred_LogisticRegression)
      self.accuracy_DecisionTreeClassifier = self.accuracy_score(self.y_test, self.y_pred_DecisionTreeClassifier)
      self.accuracy_MLPClassifier = self.accuracy_score(self.y_test, self.y_pred_MLPClassifier)

      out.add(f'Acuratetea modelului RandomForestClassifier este: {self.accuracy_RandomForestClassifier:.2f}')
      out.add(f'Acuratetea modelului SVC este: {self.accuracy_SVC:.2f}')
      out.add(f'Acuratetea modelului LogisticRegression este: {self.accuracy_LogisticRegression:.2f}')
      out.add(f'Acuratetea modelului DecisionTreeClassifier este: {self.accuracy_DecisionTreeClassifier:.2f}')
      out.add(f'Acuratetea modelului MLPClassifier este: {self.accuracy_MLPClassifier:.2f}')

  def create_table(self):
    global out
    from tabulate import tabulate

    #create data
    data = [["RandomForestClassifier Model", self.accuracy_RandomForestClassifier], 
            ["SVC Model", self.accuracy_SVC], 
            ["LogisticRegression Model", self.accuracy_LogisticRegression], 
            ["DecisionTreeClassifier Model", self.accuracy_DecisionTreeClassifier],
            ["MLPClassifier Model", self.accuracy_MLPClassifier]]
  
    #define header names
    col_names = ["Models", "Accuracy"]
  
    #display table
    out.add("\n")
    out.add(tabulate(data, headers=col_names))

dir = "train"
p = Preprocessing(dir)
x, y = p.preprocesare()

m = Model()
m.train(x, y)
m.models_accuracy()
m.create_table()

print("erori:")
err.show()
err.clear()
print("output:")
out.show()
out.clear()

# forma adnotarilor: [eticheta emotie] [etichete fundal] [eticheta personaj] text
# eticheta emotie poate avea urmatoarele valori:
#   A = anger
#   B = boredeom
#   D = disgust
#   F = fear or anxiety
#   H = happiness
#   I = irritation or nervousness
#   N = neutral
#   S = sadness
# eticheta fundal poate avea urmatoarele valori:
#   zgomot - pt zona de zgomot
#   zgomot fundal - pt zgomotul de fundal
#   voci - pt voci nedeslusite
#   voci fundal - pentru vocile care se aud pe fundal
#   tipete fundal - pentru vocile de pe fundal care dau impresia de spaima, frica
#   muzica - pt zona de muzica
#   muzica fundal - pt muzica care se aude pe fundal
# eticheta personaj poate avea urmatoarele valori:#
#   apelant - cel care suna la 112
#   operator - cel care raspunde la telefon
#   voci - cel care se aude nu este niciunul dintre cele doua personaje
# text - zona de text reprezentand ceea ce zice personajul

# exemplu folosire model dupa ce a fost antrenat

# in caz ca a fost salvat modelul itr-un fisier
#with open('model.pkl', 'rb') as file:
#    model = pickle.load(file)

# incarcati fisierul audio
audio, sr = librosa.load("audio_file.wav")

# extrageti caracteristicile fisierului audio
X = extract_features(audio, sr)

# preprocesati caracteristicile
X = StandardScaler().fit_transform(X.reshape(1, -1))

# folositi modelul pentru a face predictia
prediction_RandomForestClassifierModel = RandomForestClassifierModel.predict(X)
prediction_SVCModel = SVCModel.predict(X)
prediction_LogisticRegressionModel = LogisticRegressionModel.predict(X)
prediction_DecisionTreeClassifierModel = DecisionTreeClassifierModel.predict(X)
prediction_MLPClassifierModel = MLPClassifierModel.predict(X)
#prediction = model.predictModel.predict(X)

# transformati rezultatul predictiei in eticheta de emotie
label_encoder = LabelEncoder()
emotion_labels = label_encoder.fit_transform(["A", "B", "D", "F", "H", "I", "S", "N"])
emotion_RandomForestClassifierModel = emotion_labels[prediction_RandomForestClassifierModel[0]]
emotion_SVCModel = emotion_labels[prediction_SVCModel[0]]
emotion_LogisticRegressionModel = emotion_labels[prediction_LogisticRegressionModel[0]]
emotion_DecisionTreeClassifierModel = emotion_labels[prediction_DecisionTreeClassifierModel[0]]
emotion_MLPClassifierModel = emotion_labels[prediction_MLPClassifierModel[0]]

# faceți predicții pentru caracteristicile extrase folosind modelul antrenat
predictions = model.predict(X)

print(predictions)